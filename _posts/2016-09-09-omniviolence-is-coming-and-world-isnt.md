---
title: 'Omniviolence Is Coming and the World Isn’t Ready'
date: 2019-10-22T01:21:00+01:00
draft: false
---

![](http://static.nautil.us/16512_41621ff11046c80c435fa90489a3a20d.png)

_Emerging bio-, nano-, and cyber-technologies are enabling criminals to target anyone anywhere and, due to democratization, increasingly at scale._Screengrab via [_The Future of Life Institute_/YouTube](https://www.youtube.com/watch?v=HipTO_7mUOw)

In _The Future of Violence_, Benjamin Wittes and Gabriella Blum discuss a disturbing hypothetical scenario. A lone actor in Nigeria, “home to a great deal of spamming and online fraud activity,” tricks women and teenage girls into downloading malware that enables him to monitor and record their activity, for the purposes of blackmail. The real story involved a California man who the FBI eventually caught and sent to prison for six years, but if he had been elsewhere in the world he might have gotten away with it. Many countries, as Wittes and Blum note, “have neither the will nor the means to monitor cybercrime, prosecute offenders, or extradite suspects to the United States.” 

Technology is, in other words, enabling criminals to target anyone anywhere and, due to democratization, increasingly at scale. Emerging bio-, nano-, and cyber-technologies are becoming more and more accessible. The political scientist Daniel Deudney has a word for what can result: “omniviolence.” The ratio of killers to killed, or “K/K ratio,” is falling. For example, computer scientist Stuart Russell has vividly [described](https://www.buzzfeed.com/sarahatopol/how-to-save-mankind-from-the-new-breed-of-killer-robots) how a small group of malicious agents might engage in omniviolence: “A very, very small quadcopter, one inch in diameter can carry a one-or two-gram shaped charge,” he says. “You can order them from a drone manufacturer in China. You can program the code to say: ‘Here are thousands of photographs of the kinds of things I want to target.’ A one-gram [shaped charge](https://en.wikipedia.org/wiki/Shaped_charge) can punch a hole in nine millimeters of steel, so presumably you can also punch a hole in someone’s head. You can fit about three million of those in a semi-tractor-trailer. You can drive up I-95 with three trucks and have 10 million weapons attacking New York City. They don’t have to be very effective, only 5 or 10% of them have to find the target.” Manufacturers will be producing millions of these drones, available for purchase just as with guns now, Russell points out, “except millions of guns don’t matter unless you have a million soldiers. You need only three guys to write the program and launch.” In this scenario, the K/K ratio could be perhaps 3/1,000,000, assuming a 10-percent accuracy and only a single one-gram shaped charge per drone. 

> Will emerging technologies make the state system obsolete? It’s hard to see why not.

That’s completely—and horrifyingly—unprecedented. The terrorist or psychopath of the future, however, will have not just the Internet or drones—called “slaughterbots” in [this video](https://www.youtube.com/watch?v=HipTO_7mUOw) from the Future of Life Institute—but also synthetic biology, nanotechnology, and advanced AI systems at their disposal. These tools make wreaking havoc across international borders trivial, which raises the question: Will emerging technologies make the state system obsolete? It’s hard to see why not. What justifies the existence of the state, English philosopher Thomas Hobbes argued, is a “social contract.” People give up certain freedoms in exchange for state-provided security, whereby the state acts as a neutral “referee” that can intervene when people get into disputes, punish people who steal and murder, and enforce contracts signed by parties with competing interests.   

The trouble is that if anyone anywhere can attack anyone anywhere else, then states will become—and are becoming—unable to satisfy their primary duty as referee. It’s a trend toward anarchy, “the war of all against all,” as Hobbes put it—in other words a condition of everyone living in constant fear of being harmed by their neighbors. Indeed, in a recent [paper](https://www.nickbostrom.com/papers/vulnerable.pdf), “The Vulnerable World Hypothesis,” published in _Global Policy_, the Oxford philosopher Nick Bostrom argues that the only way to defend against a global catastrophe is to employ a universal and invasive surveillance system, what he calls a “High-tech Panopticon.” Sound dystopian? It sure does to me. “Creating and operating the High-tech Panopticon would require substantial investment,” Bostrom writes, “but thanks to the falling price of cameras, data transmission, storage, and computing, and the rapid advances in AI-enabled content analysis, it may soon become both technologically feasible and affordable.” Bostrom is well-aware of the downsides—corrupt actors in a state could exploit this surveillance for totalitarian ends, or hackers could blackmail unsuspecting victims. Yet the fact is that it may still be a better option than suffering one global catastrophe after another. 

How can societies counterattack omniviolence? One [strategy](https://docs.wixstatic.com/ugd/d9aaad_ed21c18c057243c3b2a6b583c985265d.pdf) could be a superintelligent machine—essentially, an extremely powerful algorithm—that’s specifically designed to govern fairly. We could then put the algorithm in political charge and, insofar as it governs as something like a “Philosopher King,” not worry constantly about the data collected being misused or abused. Of course, this is a fantastical proposal. Even the real-world use of AI in the justice system is fraught with [problems](https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/). But at this point, do we have a better idea for preventing the collapse of the state system under the weight of widespread technological empowerment?

Perhaps a completely new idea will emerge that can preserve the current system—if we even want it preserved. Or perhaps emerging technologies won’t empower people as much as I and others anticipate. It could be that offensive technologies will actually lag behind defensive technologies, making it very difficult to execute a successful attack. It could also be that before omniviolence and democratization undercut the state, civilization collapses because of climate change-linked stressors like lethal heatwaves, megadroughts, coastal flooding, rising sea-levels, melting glaciers and polar ice caps, desertification, food supply disruptions, disease outbreaks, biodiversity loss, species extinctions, and mass migrations. If we ended up living as hunter-gatherers again, the main worry would be sticks and stones, not designer pathogens and artificial intelligence.

Civilization is an experiment. We may not get the results we’re expecting. So humanity would do well to hope for the best but prepare for the worst.

_Phil Torres is a scholar of global catastrophic risks, and author of several books. His [essay](https://docs.wixstatic.com/ugd/d9aaad_ed21c18c057243c3b2a6b583c985265d.pdf), “Superintelligence and the Future of Governance: On Prioritizing the Control Problem at the End of History,” appears in the 2018 anthology,_ Artificial Intelligence Safety and Security_. His articles have been published in_ TIME_, Slate,_ Nautilus_, Motherboard, and the Bulletin of the Atomic Scientists. Follow him on Twitter [@xriskology](https://twitter.com/xriskology)._  

Get the Nautilus newsletter

The newest and most popular articles delivered right to your inbox!

  
  
from Hacker News https://ift.tt/2pIuxJ3