---
title: 'YouTubeâ€™s Rabbit Hole of Radicalization [pdf]'
date: 2019-12-29T01:38:00+01:00
draft: false
---

Title:Algorithmic Extremism: Examining YouTube's Rabbit Hole of Radicalization
==============================================================================

(Submitted on 24 Dec 2019)

> Abstract: The role that YouTube and its behind-the-scenes recommendation algorithm plays in encouraging online radicalization has been suggested by both journalists and academics alike. This study directly quantifies these claims by examining the role that YouTube's algorithm plays in suggesting radicalized content. After categorizing nearly 800 political channels, we were able to differentiate between political schemas in order to analyze the algorithm traffic flows out and between each group. After conducting a detailed analysis of recommendations received by each channel type, we refute the popular radicalization claims. To the contrary, these data suggest that YouTube's recommendation algorithm actively discourages viewers from visiting radicalizing or extremist content. Instead, the algorithm is shown to favor mainstream media and cable news content over independent YouTube channels with slant towards left-leaning or politically neutral channels. Our study thus suggests that YouTube's recommendation algorithm fails to promote inflammatory or radicalized content, as previously claimed by several outlets.

Submission history
------------------

From: Anna Zaitsev \[

[view email](https://arxiv.org/show-email/466d0671/1912.11211)

\]

**\[v1\]**

Tue, 24 Dec 2019 05:09:01 UTC (5,555 KB)

  
  
from Hacker News https://ift.tt/2F1xTeE